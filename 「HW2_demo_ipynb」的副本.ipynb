{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whitebearOuO/Bootstrap-starburst/blob/main/%E3%80%8CHW2_demo_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEMO2 : 聊天機器人\n",
        "\n",
        "資料集: [Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization](https://arxiv.org/abs/1808.08745)\n",
        "\n",
        "程式碼參考自: [huggingface](https://huggingface.co/)\n",
        "\n",
        "> **資料集說明**\n",
        "\n",
        "We introduce extreme summarization, a new single-document summarization task which does not favor extractive strategies and calls for an abstractive modeling approach. The idea is to create a short, one-sentence news summary answering the question \"What is the article about?\". We collect a real-world, large-scale dataset for this task by harvesting online articles from the British Broadcasting Corporation (BBC).\n",
        "\n",
        "**訓練一個Encode-Decoder模型，輸入是一句話，輸出為一句話。**\n",
        "\n",
        "程式碼參考自：\n",
        "1. [Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models](https://arxiv.org/pdf/1907.12461.pdf)\n",
        "2. [huggingface](https://huggingface.co/docs/transformers/model_doc/encoder-decoder)"
      ],
      "metadata": {
        "id": "u4Lcxy3OWGr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mqKY76UWK3z",
        "outputId": "a3c76695-b7e0-499e-83c6-4c362b7cb809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.14.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, EncoderDecoderModel\n",
        "import torch\n",
        "import transformers\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # setting ignore as a parameter"
      ],
      "metadata": {
        "id": "DEgv6xGtWOFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 一些模型會用到的小函數"
      ],
      "metadata": {
        "id": "YUlTeUghWdLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform logits to token ids\n",
        "def get_pred(logits):\n",
        "  '''\n",
        "  Parameter\n",
        "  ---------\n",
        "  logits: torch.tensor, model outputs (batch_size, max_length, vocab_size)\n",
        "  ---------\n",
        "  '''\n",
        "  return logits.argmax(dim=-1)\n",
        "\n",
        "# transform token id to word\n",
        "def transform(ids):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(parameters['tokenizer'])\n",
        "    return tokenizer.batch_decode(ids, skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "h_rw80-YWp4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROUGE（Recall-Oriented Understudy for Gisting Evaluation）為一種自動摘要評價方法，是評估自動文摘以及機器翻譯的一組指標。\n",
        "\n",
        "ROUGE 將系統生成的自動摘要與人工生成的標準摘要相對比，通過統計二者之間重疊的 n-gram 數目，來評價摘要的質量，是一種基於 n-gram 召回率的評價方法。\n",
        "\n",
        "程式碼參考：[ROUGE score](https://torchmetrics.readthedocs.io/en/stable/text/rouge_score.html)"
      ],
      "metadata": {
        "id": "dyqW8vonWuHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate rouge comfusion metrics\n",
        "from torchmetrics.functional.text.rouge import rouge_score\n",
        "\n",
        "def cal_metrics(pred, ans, method):\n",
        "    '''\n",
        "    Parameter\n",
        "    ---------\n",
        "    pred: [list], predict sentences\n",
        "    ans: [list], true sentence\n",
        "    method: 'rouge1', 'rouge2', 'rougeL'. 'rougeLsum'.\n",
        "    ---------\n",
        "    '''\n",
        "    score = rouge_score(transform(pred), transform(ans))\n",
        "    f1 = score[method+'_fmeasure']\n",
        "    rec = score[method+'_recall']\n",
        "    prec = score[method+'_precision']\n",
        "\n",
        "    return f1, rec, prec"
      ],
      "metadata": {
        "id": "i8dGrtPaWySd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model to path\n",
        "def save_checkpoint(save_path, model):\n",
        "    if save_path == None:\n",
        "        return\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "# load model from path\n",
        "def load_checkpoint(load_path, model, device):\n",
        "    if load_path==None:\n",
        "        return\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "\n",
        "    model.load_state_dict(state_dict)\n",
        "    return model"
      ],
      "metadata": {
        "id": "C4rcF3RPW5tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 載入資料"
      ],
      "metadata": {
        "id": "UDPYdPHKXEFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 資料集下載\n",
        "\n",
        "- 資料集說明 :\n",
        "  - document: Input news article.\n",
        "  - summary: One sentence summary of the article.\n",
        "  - id: BBC ID of the article.\n",
        "\n",
        "You can see https://huggingface.co/datasets/xsum to get more information."
      ],
      "metadata": {
        "id": "ufWy-DrJXFRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"xsum\")"
      ],
      "metadata": {
        "id": "_tyrdvW-XPui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7NDw8ExXVld",
        "outputId": "09af67c1-4019-41b4-a4d8-dc389e731111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 204045\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 11332\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 11334\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "看一下資料格式長怎樣"
      ],
      "metadata": {
        "id": "HuGREFk3Xd2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo6-5en9XfSp",
        "outputId": "fe2e991f-81cc-4c8c-d86e-eecfd6f72f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'document': 'The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\\nRepair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\\nTrains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\\nMany businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\\nFirst Minister Nicola Sturgeon visited the area to inspect the damage.\\nThe waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\\nJeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\\nHowever, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\\n\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we\\'re neglected or forgotten,\" she said.\\n\"That may not be true but it is perhaps my perspective over the last few days.\\n\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\\nMeanwhile, a flood alert remains in place across the Borders because of the constant rain.\\nPeebles was badly hit by problems, sparking calls to introduce more defences in the area.\\nScottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\\nThe Labour Party\\'s deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\\nHe said it was important to get the flood protection plan right but backed calls to speed up the process.\\n\"I was quite taken aback by the amount of damage that has been done,\" he said.\\n\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\\nHe said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\\nHave you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.',\n",
              " 'summary': 'Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.',\n",
              " 'id': '35232142'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(dataset['train'])\n",
        "val_df = pd.DataFrame(dataset['validation'])\n",
        "test_df = pd.DataFrame(dataset['test'])\n",
        "\n",
        "print(type(train_df['document'][0]))\n",
        "\n",
        "print('# of train_df:', len(train_df))\n",
        "print('# of dev_df:', len(val_df))\n",
        "print('# of test_df data:', len(test_df))\n",
        "\n",
        "# save data\n",
        "train_df.to_csv('./train.tsv', sep='\\t', index=False)\n",
        "val_df.to_csv('./val.tsv', sep='\\t', index=False)\n",
        "test_df.to_csv('./test.tsv', sep='\\t', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdKM6iGkXj5T",
        "outputId": "25fcd132-4444-4824-859f-46e9d41fbb70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "# of train_df: 204045\n",
            "# of dev_df: 11332\n",
            "# of test_df data: 11334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 自定義 Dataset，將tokenzie的步驟放進去\n",
        "\n",
        "我們會將資料用 Dataset + Dataloader 封裝"
      ],
      "metadata": {
        "id": "dfl4eq3AXpXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, df, args):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        df: (DataFrame) input data\n",
        "        specify: (str) decide which column of df will use\n",
        "        args: (dict) parameters\n",
        "        '''\n",
        "        self.df = df\n",
        "        self.encoder_max_length = args['encoder_max_length']\n",
        "        self.decoder_max_length = args['decoder_max_length']\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(args['tokenizer'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def tokenize(self, row):\n",
        "        # tokenize the inputs and labels\n",
        "        data = {}\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "                row[\"document\"],\n",
        "                None,\n",
        "                add_special_tokens=True,\n",
        "                max_length=self.encoder_max_length,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                return_token_type_ids=True\n",
        "              )\n",
        "        outputs = self.tokenizer.encode_plus(\n",
        "                row[\"summary\"],\n",
        "                None,\n",
        "                add_special_tokens=True,\n",
        "                max_length=self.decoder_max_length,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                return_token_type_ids=True\n",
        "              )\n",
        "\n",
        "\n",
        "        data[\"document\"] = row[\"document\"]\n",
        "        data[\"summary\"] = row[\"summary\"]\n",
        "        data[\"input_ids\"] = torch.tensor(inputs.input_ids, dtype=torch.long)\n",
        "        data[\"attention_mask\"] = torch.tensor(inputs.attention_mask, dtype=torch.long)\n",
        "        data[\"decoder_attention_mask\"] = torch.tensor(outputs.attention_mask, dtype=torch.long)\n",
        "        data[\"labels\"] = torch.tensor(outputs.input_ids, dtype=torch.long)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        vectors = self.tokenize(self.df.loc[index])\n",
        "\n",
        "        return vectors"
      ],
      "metadata": {
        "id": "yBnmOEjhXqoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 定義你的 Hyperparameters\n",
        "\n",
        "* 如果電腦的記憶體不夠可以試著減少 batch_size\n",
        "* 因為我們採用現有的模型去fine-tune，所以一般不需要設太多 epochs\n",
        "* config 就是我們所使用的現有模型，可以自己找適合的做替換\n",
        "* 如果你的模型 overfit 了，可以試著把 dropout 調高\n",
        "* 可以試著調高或調低 learning_rate，這會影響他的學習速度（跨步的大小）\n",
        "* 你應該先檢閱你的資料再來決定 max_len"
      ],
      "metadata": {
        "id": "6ddc20KtYC-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "parameters = {\n",
        "    \"tokenizer\": 'bert-base-uncased', #這三個可以不一樣\n",
        "    \"config1\": 'bert-base-uncased', # encoder\n",
        "    \"config2\": 'bert-base-uncased', # decoder,\n",
        "    \"decoder_max_length\": 512,\n",
        "    \"encoder_max_length\": 512,\n",
        "    \"learning_rate\": 1e-2,\n",
        "    \"epochs\": 3,\n",
        "    \"batch_size\": 2, #記憶體不夠就調小\n",
        "    \"dropout\": 0.1, #overfit就調高\n",
        "}"
      ],
      "metadata": {
        "id": "u805siR4YIy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 開始訓練"
      ],
      "metadata": {
        "id": "U9XsjVB3YKD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 為了方便演示，這次的資料都沒有全部丟下去，而是sample部分資料，減少所需花費時長\n",
        "* 如想達到更高效能，建議增加資料量以及epochs數量"
      ],
      "metadata": {
        "id": "0tw3pxzZYMTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import pandas as pd\n",
        "\n",
        "# load training data\n",
        "train_df = pd.read_csv('./train.tsv', sep = '\\t').dropna().sample(1000).reset_index(drop=True) #數字可調\n",
        "train_dataset = CustomDataset(train_df, parameters)\n",
        "train_loader = DataLoader(train_dataset, batch_size=parameters['batch_size'], shuffle=True)\n",
        "\n",
        "# load validation data\n",
        "val_df = pd.read_csv('./val.tsv', sep = '\\t').dropna().sample(250).reset_index(drop=True)\n",
        "val_dataset = CustomDataset(val_df, parameters)\n",
        "val_loader = DataLoader(val_dataset, batch_size=parameters['batch_size'], shuffle=True)\n",
        "\n",
        "print('load training data : %d'%(len(train_dataset)))\n",
        "print('load validation data : %d'%(len(val_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrpz-feTYOO1",
        "outputId": "af325f9e-ec9d-4d2b-ca42-12ab5819cc9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load training data : 1000\n",
            "load validation data : 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   載入模型（這邊會使用已經訓練過的模型，Fine-tune我們的資料集）\n",
        "*   定義Optimization\n",
        "  *   通常用Adam就可以了，你也可以換SGD之類的試看看\n",
        "  *   可以自己看需不需要加scheduler（可以自己寫一個function，也可以直接套用現有的function）\n",
        "  \n",
        "  ［請記得pytorch中是以step去計算，想要用epoch去訂定需自行換算］"
      ],
      "metadata": {
        "id": "9uza7gg0YX6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, EncoderDecoderModel\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transformers.logging.set_verbosity_error() # close the warning message\n",
        "tokenizer = AutoTokenizer.from_pretrained(parameters['tokenizer'])\n",
        "\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(parameters['config1'], parameters['config2']).to(device)\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.eos_token_id = tokenizer.sep_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.max_length = parameters['encoder_max_length']\n",
        "model.config.vocab_size = model.config.decoder.vocab_size"
      ],
      "metadata": {
        "id": "dTXtkYwvYY_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXjhdKiTYkMx",
        "outputId": "105ef0cc-3418-47f2-87da-45b86273f4e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderDecoderModel(\n",
              "  (encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (decoder): BertLMHeadModel(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-11): 12 x BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSdpaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSdpaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (cls): BertOnlyMLMHead(\n",
              "      (predictions): BertLMPredictionHead(\n",
              "        (transform): BertPredictionHeadTransform(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (transform_act_fn): GELUActivation()\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## You can custom your optimizer ##\n",
        "# we use Adam here\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=parameters['learning_rate'], betas=(0.9, 0.98), eps=1e-9)"
      ],
      "metadata": {
        "id": "LkWdnnbpYopG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate dataloader\n",
        "def evaluate(model, data_loader, args, device):\n",
        "    val_loss, val_f1, val_rec, val_prec = 0.0, 0.0, 0.0, 0.0\n",
        "    step_count = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            input_ids = data[\"input_ids\"].to(device)\n",
        "            attention_mask = data[\"attention_mask\"].to(device)\n",
        "            decoder_attention_mask = data[\"decoder_attention_mask\"].to(device)\n",
        "            labels = data[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    decoder_attention_mask=decoder_attention_mask,\n",
        "                    labels=labels,\n",
        "                    output_attentions=True\n",
        "                    )\n",
        "\n",
        "            loss, logits = outputs.loss, outputs.logits\n",
        "            f1, rec, prec = cal_metrics(get_pred(logits), labels, 'rouge1')\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_f1 += f1\n",
        "            val_rec += rec\n",
        "            val_prec += prec\n",
        "            step_count += 1\n",
        "\n",
        "        val_loss = val_loss / step_count\n",
        "        val_f1 = val_f1 / step_count\n",
        "        val_rec = val_rec / step_count\n",
        "        val_prec = val_prec / step_count\n",
        "\n",
        "    return val_loss, val_f1, val_rec, val_prec"
      ],
      "metadata": {
        "id": "nFdc7BUtYu_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-KlmAMsYzDe",
        "outputId": "48d72f4a-eda7-4d3c-9885-f1104f690997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "import time\n",
        "metrics = ['loss', 'acc', 'f1', 'rec', 'prec']\n",
        "mode = ['train_', 'val_']\n",
        "record = {s+m :[] for s in mode for m in metrics}\n",
        "\n",
        "for epoch in range(parameters[\"epochs\"]):\n",
        "\n",
        "    st_time = time.time()\n",
        "    train_loss, train_f1, train_rec, train_prec = 0.0, 0.0, 0.0, 0.0\n",
        "    step_count = 0\n",
        "\n",
        "    model.train()\n",
        "    for data in train_loader:\n",
        "\n",
        "        input_ids = data[\"input_ids\"].to(device)\n",
        "        attention_mask = data[\"attention_mask\"].to(device)\n",
        "        decoder_attention_mask = data[\"decoder_attention_mask\"].to(device)\n",
        "        labels = data[\"labels\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                decoder_attention_mask=decoder_attention_mask,\n",
        "                labels=labels,\n",
        "                output_attentions=True\n",
        "                )\n",
        "        loss, logits = outputs.loss, outputs.logits\n",
        "        f1, rec, prec = cal_metrics(get_pred(logits), labels, 'rouge1')\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        train_f1 += f1\n",
        "        train_rec += rec\n",
        "        train_prec += prec\n",
        "        step_count += 1\n",
        "\n",
        "    val_loss, val_f1, val_rec, val_prec = evaluate(model, val_loader, parameters, device)\n",
        "\n",
        "    train_loss = train_loss / step_count\n",
        "    train_f1 = train_f1 / step_count\n",
        "    train_rec = train_rec / step_count\n",
        "    train_prec = train_prec / step_count\n",
        "\n",
        "    print('[epoch %d] cost time: %.4f s'%(epoch + 1, time.time() - st_time))\n",
        "    print('         loss     f1      rec    prec')\n",
        "    print('train | %.4f, %.4f, %.4f, %.4f'%(train_loss, train_f1, train_rec, train_prec))\n",
        "    print('val   | %.4f, %.4f, %.4f, %.4f,\\n'%(val_loss, val_f1, val_rec, val_prec))\n",
        "\n",
        "    # record training metrics of each training epoch\n",
        "    record['train_loss'].append(train_loss)\n",
        "    record['train_f1'].append(train_f1)\n",
        "    record['train_rec'].append(train_rec)\n",
        "    record['train_prec'].append(train_prec)\n",
        "\n",
        "    record['val_loss'].append(val_loss)\n",
        "    record['val_f1'].append(val_f1)\n",
        "    record['val_rec'].append(val_rec)\n",
        "    record['val_prec'].append(val_prec)"
      ],
      "metadata": {
        "id": "KrvPDF62Y0Lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "save_checkpoint('./bert.pt', model)"
      ],
      "metadata": {
        "id": "6hlnSTOcY-Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# draw learning curve\n",
        "import matplotlib.pyplot as plt\n",
        "def draw_pics(record, name, img_save=False, show=False):\n",
        "    x_ticks = range(1, parameters['epochs']+1)\n",
        "\n",
        "    plt.figure(figsize=(6, 3))\n",
        "\n",
        "    plt.plot(x_ticks, record['train_'+name], '-o', color='lightskyblue',\n",
        "             markeredgecolor=\"teal\", markersize=3, markeredgewidth=1, label = 'Train')\n",
        "    plt.plot(x_ticks, record['val_'+name], '-o', color='pink',\n",
        "             markeredgecolor=\"salmon\", markersize=3, markeredgewidth=1, label = 'Val')\n",
        "    plt.grid(color='lightgray', linestyle='--', linewidth=1)\n",
        "\n",
        "    plt.title('Model', fontsize=14)\n",
        "    plt.ylabel(name, fontsize=12)\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.xticks(x_ticks, fontsize=12)\n",
        "    plt.yticks(fontsize=12)\n",
        "    plt.legend(loc='lower right' if not name.lower().endswith('loss') else 'upper right')\n",
        "\n",
        "    if img_save:\n",
        "        plt.savefig(name+'.png', transparent=False, dpi=300)\n",
        "    if show:\n",
        "        plt.show()\n",
        "\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "3oZc55KwZAZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_pics(record, 'loss', img_save=False, show=True)\n",
        "draw_pics(record, 'f1', img_save=False, show=True)"
      ],
      "metadata": {
        "id": "WTy11-5DZEIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 預測結果"
      ],
      "metadata": {
        "id": "wns0kekjZMkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### generate function\n",
        "\n",
        "huggingface中有繼承PretrainedModel的模型都有generate function，是一個已經封裝好的函數，可以直接使用\n",
        "\n",
        "我們看一下直接使用去預測的結果為何"
      ],
      "metadata": {
        "id": "2BGaivd1ZNUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, EncoderDecoderModel\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(parameters['tokenizer'])\n",
        "finetune_model = EncoderDecoderModel.from_encoder_decoder_pretrained(parameters['config1'], parameters['config2']).to(device)\n",
        "finetune_model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "finetune_model.config.eos_token_id = tokenizer.sep_token_id\n",
        "finetune_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "finetune_model.config.max_length = parameters['encoder_max_length']\n",
        "finetune_model.config.vocab_size = finetune_model.config.decoder.vocab_size\n",
        "\n",
        "# let's perform inference on a long piece of text\n",
        "inputs = (\n",
        "    \"scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\n",
        ")\n",
        "input_ids = tokenizer(inputs, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "# autoregressively generate summary (uses greedy decoding by default)\n",
        "generated_ids = finetune_model.generate(input_ids)\n",
        "generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "qecMZysFZPEy",
        "outputId": "9a35b329-bb73-4286-d701-0f5067654cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-369fdf987fee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncoderDecoderModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfinetune_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderDecoderModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_encoder_decoder_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 預測單筆句子\n",
        "* 因為沒有訓練很久 & 資料量不多，所以結果沒有很好"
      ],
      "metadata": {
        "id": "axATMlOeZhSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict single sentence\n",
        "def predict_one(query, model, tokenizer, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        inputs = tokenizer.encode_plus(\n",
        "                query,\n",
        "                None,\n",
        "                add_special_tokens=True,\n",
        "                max_length = parameters[\"encoder_max_length\"],\n",
        "                truncation = True,\n",
        "                padding = 'max_length',\n",
        "                return_token_type_ids=True\n",
        "            )\n",
        "        query_ids = torch.tensor([inputs.input_ids], dtype=torch.long).to(device)\n",
        "        attention_mask = torch.tensor([inputs.attention_mask], dtype=torch.long).to(device)\n",
        "        outputs = model(input_ids=query_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    decoder_attention_mask=attention_mask,\n",
        "                    labels=query_ids\n",
        "                    )\n",
        "        pred_ids = get_pred(outputs.logits)\n",
        "        pred_sentence = transform(pred_ids)\n",
        "        return pred_sentence"
      ],
      "metadata": {
        "id": "WF_wqGWuZjKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = \"scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(parameters['tokenizer'])\n",
        "pred = predict_one(inputs, model, tokenizer, device)\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "o3MViELcZmqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 先初始化一個相同架構模型，再讀入已訓練好的模型參數"
      ],
      "metadata": {
        "id": "zxLV95UxZpt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load model from training result\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "init_model = EncoderDecoderModel.from_encoder_decoder_pretrained(parameters['config1'], parameters['config2'])\n",
        "init_model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "init_model.config.eos_token_id = tokenizer.sep_token_id\n",
        "init_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "init_model.config.max_length = parameters['encoder_max_length']\n",
        "init_model.config.vocab_size = init_model.config.decoder.vocab_size\n",
        "\n",
        "final_model = load_checkpoint('./bert.pt', init_model, device).to(device)"
      ],
      "metadata": {
        "id": "MW8rG_ACZqYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = predict_one(inputs, final_model, tokenizer, device)\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "i3_7nTM6ZuKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate testing data\n",
        "test_df = pd.read_csv('./test.tsv', sep = '\\t').dropna().sample(500).reset_index(drop=True)\n",
        "test_dataset = CustomDataset(test_df, parameters)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "test_loss, test_f1, test_rec, test_prec = evaluate(final_model, test_loader, parameters, device)\n",
        "print('test_f1: %.4f'%(test_f1))"
      ],
      "metadata": {
        "id": "cDVqezvBZu75"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}